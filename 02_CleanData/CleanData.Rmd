---
title: "CleanData"
author: "MJ"
date: "24/03/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Remove previous data from environment
rm(list = ls())
```

```{r}
library(arrow) # needed to read parquet file
library(dplyr)
library(car)
library(caret)
library(ggplot2)
library(corrplot)
```

## Read & View the Data
```{r}
# path to the project folder
#setwd("C:/Users/mjafarpour/Downloads/MGT_6203_GroupProject/")
file_path <- "../01_RawData/nfip_Houston_flood_policies.parquet"
policy_df <- read_parquet(file_path, as_tibble = TRUE)
head(policy_df)
```

## I filter the dataset again for Texas only 
```{r}
## Filter propertystate = 'TX"
policy_df <- subset(policy_df, propertystate == 'TX' )
```


```{r}
policy_df = subset(policy_df,select=-c(agriculturestructureindicator, propertystate, reportedcity, houseofworshipindicator,nonprofitindicator,regularemergencyprogramindicator,smallbusinessindicatorbuilding,hfiaasurcharge))
View(policy_df)
```

```{r}
# count NA values in each column
colSums(is.na(policy_df))
```

## Continue fiter some columns with large number of NA

```{r}
# Filter more columns with significant number of NA values
policy_df = subset(policy_df,select=-c(basefloodelevation,cancellationdateoffloodpolicy, countycode, elevationcertificateindicator, lowestadjacentgrade, lowestfloorelevation, obstructiontype))                          
View(policy_df)
```

```{r}
# Number of NA values in each column
colSums(is.na(policy_df))
```
```{r}
## Observe unique value in each column

categorical_col <- policy_df[c("condominiumindicator", "construction", "elevatedbuildingindicator", "floodzone", "locationofcontents", "postfirmconstructionindicator", "primaryresidenceindicator")]

count_unique <- rapply(categorical_col, function(x) length(unique(x)))
count_unique
```
## Some category variable neeed to clarify:
## condominiumindicator (6), construction (3), elevatedbuildingindicator(3), floodzone (33), locationofcontents (7), postfirmconstructionindicator (3), primaryresidenceindicator (3)
```{r}
# condominiumindicator variables

unique(policy_df$condominiumindicator)
unique(policy_df$locationofcontents)

```
```{r}
#condominum indicator for lower level and upper level condo
policy_df$lowerlevelcondo=ifelse(policy_df$condominiumindicator=='L',1,0)
policy_df$upperlevelcondo=ifelse(policy_df$condominiumindicator=='U',1,0)

# Construction
policy_df$construction=ifelse(policy_df$construction=='Y',1,0)

#elevatedbuildingindicator
policy_df$elevatedbuildingindicator=ifelse(policy_df$elevatedbuildingindicator=='Y',1,0)


#trying to factor the locationofcontents column ....feel free to advise anyother column names. 
policy_df$lowerflooronly=ifelse(policy_df$locationofcontents=='Lowest floor only above ground level (No basement/enclosure/crawlspace/subgrade crawlspace)',1,0)
policy_df$upperandlowerfloors=ifelse(policy_df$locationofcontents=='Lowest floor above ground level and higher floors (No basement/enclosure/crawlspace/subgrade crawlspace)',1,0)
policy_df$basementandabove=ifelse(policy_df$locationofcontents=='Basement/Enclosure/Crawlspace/Subgrade Crawlspace and above',1,0)
policy_df$basementonly=ifelse(policy_df$locationofcontents=='Basement/Enclosure/Crawlspace/Subgrade Crawlspace only',1,0)
policy_df$morethan1floor=ifelse(policy_df$locationofcontents=='Above ground level more than one full floor',1,0)
policy_df$mobilehomeortrailer=ifelse(policy_df$locationofcontents==' Manufactured (mobile) home or travel trailer on foundation',1,0)

#postfirmconstructionindicator
policy_df$postfirmconstructionindicator=ifelse(policy_df$postfirmconstructionindicator=='Y',1,0)

#primaryresidenceindicator
policy_df$primaryresidenceindicator=ifelse(policy_df$primaryresidenceindicator=='Y',1,0)
```


```{r}
# Continue remove category variables

df = subset(policy_df,select=-c(condominiumindicator, locationofcontents))
View(df)
```


```{r}
## Type of data in all columns
str(df)
```
```{r}
# Convert all date from numeric to date format

date_cols <- c("originalconstructiondate", "originalnbdate", "policyeffectivedate", "policyterminationdate")

df1 <- df %>%
   mutate_at(vars(all_of(date_cols)), funs(as.Date(., "%Y-%m-%d")))

str(df1)
```
```{r}
#identify all character columns
df2 <- subset(df1, select = -c(floodzone))

chars <- sapply(df2, is.character)

#convert all character columns to numeric
df2[ , chars] <- as.data.frame(apply(df2[ , chars], 2, as.numeric))
str(df2)
```
```{r}
# Select continuous variables for correlation examination

df_num <- subset(df2,select = c(basementenclosurecrawlspacetype, censustract,crsdiscount,elevationdifference,federalpolicyfee, latitude, longitude, policycost, policycount, reportedzipcode, ratemethod, totalbuildinginsurancecoverage, totalcontentsinsurancecoverage))

# Examine correlation between all numeric variables

cormat <-cor(df_num, use = "pairwise.complete.obs")
cormat
```
```{r}
corrplot(cormat)
```


```{r}
# Multicollinearity
# Check the variables of highly correlated

highly_corelated = findCorrelation(cormat, cutoff = 0.6)

highlyCor_Col = colnames(df_num)[highly_corelated]
highlyCor_Col

```
```{r}
# Now, we remove highly correlated variables from original dataset and create final dataset

df_final = df2[, -which(colnames(df2) %in% highlyCor_Col)]
dim(df_final)

```
```{r}
fit = lm(totalinsurancepremiumofthepolicy ~., df_final)
summary(fit)
```
## from the output, we can remove some insignificant variables 
```{r}
fit1 = lm(totalinsurancepremiumofthepolicy ~. -censustract -latitude -longitude -originalnbdate -policytermindicator -reportedzipcode -lowerflooronly -basementonly -mobilehomeortrailer -upperlevelcondo, df_final)
summary(fit1)
```
## Very good model with high accuracy

```{r}
## Variable selections using Lasso

train_con <- trainControl(method = 'cv', number = 10) # using 10 folds cv

lasso <- train(totalinsurancepremiumofthepolicy ~., df_final,
               method = 'lasso',
               preProc = c('scale', 'center'),
               trControl = train_con,
               na.action=na.exclude)
lasso


```

