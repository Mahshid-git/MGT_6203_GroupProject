knitr::opts_chunk$set(echo = TRUE)
# Remove previous data from environment
rm(list = ls())
library(arrow) # needed to read parquet file
library(dplyr)
library(car)
library(caret)
library(ggplot2)
library(corrplot)
file_path <- "../02_CleanData/policy_clean.parquet"
df <- read_parquet(file_path, as_tibble = TRUE)
head(df)
# Select continuous variables for correlation examination
# comment
df_num <- subset(df, select = c(basementenclosurecrawlspacetype, censustract,crsdiscount,elevationdifference,federalpolicyfee, latitude, longitude, policycost, policycount, reportedzipcode, ratemethod, totalbuildinginsurancecoverage, totalcontentsinsurancecoverage))
# Examine correlation between all numeric variables
cormat <-cor(df_num, use = "pairwise.complete.obs")
cormat
corrplot(cormat)
corrplot(cormat_nonlin)
# Looking for Spearman correlation (checks nonlinear correlation too eg y=x3 ha Spearman correlation of 1)
cormat_nonlin <- cor(df_num, use = "pairwise.complete.obs", method="spearman")
# Looking for Spearman correlation (checks nonlinear correlation too eg y=x3 ha Spearman correlation of 1)
cormat_nonlin <- cor(df_num, use = "pairwise.complete.obs", method="spearman")
cormat_nonlin
corrplot(cormat_nonlin)
# Multicollinearity
# Check the variables of highly correlated
highly_corelated = findCorrelation(cormat, cutoff = 0.6)
highlyCor_Col = colnames(df_num)[highly_corelated]
highlyCor_Col
# Now, we remove highly correlated variables from original dataset and create "cleaner" dataset
df_clean = df[, -which(colnames(df) %in% highlyCor_Col)]
dim(df_clean)
View(df_clean)
fit = lm(totalinsurancepremiumofthepolicy ~., df_clean)
summary(fit)
fit1 = lm(totalinsurancepremiumofthepolicy ~. -censustract -latitude -policytermindicator -reportedzipcode  -upperlevelcondo -postfirmconstructionindicator -basementonly -mobilehomeortrailer -floodzone_modrisk -floodzone_undetermined , df_final)
fit1 = lm(totalinsurancepremiumofthepolicy ~. -censustract -latitude -policytermindicator -reportedzipcode  -upperlevelcondo -postfirmconstructionindicator -basementonly -mobilehomeortrailer -floodzone_modrisk -floodzone_undetermined , df_clean)
summary(fit1)
fit1 = lm(totalinsurancepremiumofthepolicy ~. -censustract -policytermindicator -upperlevelcondo -postfirmconstructionindicator -basementonly -mobilehomeortrailer -floodzone_modrisk -floodzone_undetermined , df_clean)
summary(fit1)
df_final <- subset(df_clean, select=-c(-censustract, policytermindicator,upperlevelcondo, postfirmconstructionindicator,basementonly,mobilehomeortrailer,floodzone_modrisk,floodzone_undetermined))
df_final <- subset(df_clean, select=-c(censustract, policytermindicator,upperlevelcondo, postfirmconstructionindicator,basementonly,mobilehomeortrailer,floodzone_modrisk,floodzone_undetermined))
df_final <- subset(df_clean, select=-c(censustract, policytermindicator,upperlevelcondo, postfirmconstructionindicator,basementonly,mobilehomeortrailer,floodzone_modrisk,floodzone_undetermined))
View(df_final)
## Variable selections using Lasso
train_con <- trainControl(method = 'cv', number = 10) # using 10 folds cv
lasso <- train(totalinsurancepremiumofthepolicy ~., df_final,
method = 'lasso',
preProc = c('scale', 'center'),
trControl = train_con,
na.action=na.exclude)
lasso
df_final <- subset(df_clean, select=-c(censustract, policytermindicator,upperlevelcondo, postfirmconstructionindicator,basementonly,mobilehomeortrailer,floodzone_modrisk,floodzone_undetermined))
View(df_final)
## Variable selections using Lasso
train_con <- trainControl(method = 'cv', number = 10) # using 10 folds cv
lasso <- train(totalinsurancepremiumofthepolicy ~., df_final,
method = 'lasso',
preProc = c('scale', 'center'),
trControl = train_con,
na.action=na.exclude)
knitr::opts_chunk$set(echo = TRUE)
# Remove previous data from environment
rm(list = ls())
library(arrow) # needed to read parquet file
library(dplyr)
library(car)
library(caret)
library(ggplot2)
library(corrplot)
file_path <- "../02_CleanData/policy_clean.parquet"
df <- read_parquet(file_path, as_tibble = TRUE)
head(df)
str(df)
# Select continuous variables for correlation examination
# comment
df_num <- subset(df, select = c(basementenclosurecrawlspacetype, censustract,crsdiscount,elevationdifference,federalpolicyfee, latitude, longitude, policycost, policycount, reportedzipcode, ratemethod, totalbuildinginsurancecoverage, totalcontentsinsurancecoverage))
# Examine correlation between all numeric variables
cormat <-cor(df_num, use = "pairwise.complete.obs")
cormat
# Multicollinearity
# Check the variables of highly correlated
highly_corelated = findCorrelation(cormat, cutoff = 0.6)
highlyCor_Col = colnames(df_num)[highly_corelated]
highlyCor_Col
# Now, we remove highly correlated variables from original dataset and create cleaner dataset
df_clean = df[, -which(colnames(df) %in% highlyCor_Col)]
dim(df_clean)
fit = lm(totalinsurancepremiumofthepolicy ~., df_clean)
summary(fit)
fit1 = lm(totalinsurancepremiumofthepolicy ~. -censustract -policytermindicator -upperlevelcondo -mobilehomeortrailer -floodzone_modrisk -floodzone_undetermined, df_clean)
summary(fit1)
fit1 = lm(totalinsurancepremiumofthepolicy ~. -censustract -policytermindicator -upperlevelcondo -mobilehomeortrailer -floodzone_modrisk -floodzone_undetermined, df_clean)
summary(fit1)
df_final <- subset(df_clean, select = -c(censustract,policytermindicator,mobilehomeortrailer, upperlevelcondo,floodzone_modrisk,floodzone_undetermined))
View(df_final)
str(df_final)
# Select only numerical columns for data analysist (leave data type in df_final)
df_num <- subset(df_final, select = -c(originalconstructiondate, originalnbdate, policyeffectivedate, policyterminationdate))
# Select only numerical columns for data analysist (leave data type in df_final)
df_num <- subset(df_final, select = -c(originalconstructiondate, originalnbdate, policyeffectivedate, policyterminationdate))
View(df_num)
# Exporting the dataframe to clean folder
file_path3 <- "../03_EDA/df_final.parquet"
write_parquet(df_final, file_path3)
# Exporting the dataframe to clean folder
# df_final includes "date" columns
file_path3 <- "../03_EDA/df_final.parquet"
write_parquet(df_final, file_path3)
# df_num includes only numeric variables for analysis
file_path4 <- "../03_EDA/df_num.parquet"
write_parquet(df_num, file_path4)
## Variable selections using Lasso
train_con <- trainControl(method = 'cv', number = 5) # using 5 folds cv
lasso <- train(totalinsurancepremiumofthepolicy ~., df_num,
method = 'lasso',
preProc = c('scale', 'center'),
trControl = train_con,
na.action=na.exclude)
lasso
# Get coef
predict.enet(lasso$finalModel, type='coefficients', s=lasso$bestTune$fraction, mode='fraction')
## Variable selections using Lasso
train_con <- trainControl(method = 'cv', number = 5) # using 5 folds cv
lasso <- train(totalinsurancepremiumofthepolicy ~., df_num,
method = 'lasso',
preProc = c('scale', 'center'),
trControl = train_con,
na.action=na.exclude)
lasso
# Exporting the dataframe to clean folder
# df_final includes "date" columns
#file_path3 <- "../03_EDA/df_final.parquet"
#write_parquet(df_final, file_path3)
# df_num includes only numeric variables for analysis
#file_path4 <- "../03_EDA/df_num.parquet"
#write_parquet(df_num, file_path4)
# Get coef
predict.enet(lasso$finalModel, type='coefficients', s=lasso$bestTune$fraction, mode='fraction')
# Get coef
#predict.enet(lasso$finalModel, type='coefficients', s=lasso$bestTune$fraction, mode='fraction')
predict(lasso$finalModel, type = "coef", mode = "fraction", s = as.numeric(lasso$bestTune))
#coefficents are reduced to zero--> these can be discraded
# Exporting the dataframe to clean folder
# df_final includes "date" columns
file_path3 <- "../03_EDA/df_final.parquet"
write_parquet(df_final, file_path3)
# df_num includes only numeric variables for analysis
file_path4 <- "../03_EDA/df_num.parquet"
write_parquet(df_num, file_path4)
# df includes only 7 variables as suggested by Lasso for analysis
df <- subset(df_num, select = c(deductibleamountincontentscoverage, federalpolicyfee, totalbuildinginsurancecoverage, totalcontentsinsurancecoverage, primaryresidenceindicator, policycost, floodzone_highrisk))
file_path5 <- "../03_EDA/df_num.parquet"
write_parquet(df, file_path5)
# Exporting the dataframe to clean folder
# df_final includes "date" columns
file_path3 <- "../03_EDA/df_final.parquet"
write_parquet(df_final, file_path3)
# df_num includes only numeric variables for analysis
file_path4 <- "../03_EDA/df_num.parquet"
write_parquet(df_num, file_path4)
# df includes only 7 variables as suggested by Lasso for analysis
df <- subset(df_num, select = c(deductibleamountincontentscoverage, federalpolicyfee, totalbuildinginsurancecoverage, totalcontentsinsurancecoverage, primaryresidenceindicator, policycost, floodzone_highrisk))
file_path5 <- "../03_EDA/df.parquet"
write_parquet(df, file_path5)
View(df)
