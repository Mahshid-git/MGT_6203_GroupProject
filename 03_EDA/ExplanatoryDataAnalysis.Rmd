---
title: "Untitled"
author: "MJ"
date: "02/04/2022"
output: html_document
---
# This part mainly examines feature selection of the most relevant predictor variables. Different methods are used including remove multicollinearity, linear regression to remove insignificant variables, Lasso


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Remove previous data from environment
rm(list = ls())
```

```{r include=FALSE}

library(arrow) # needed to read parquet file
library(plyr)
library(dplyr)
library(car)
library(caret)
library(rattle)
library(rpart.plot)
library(rpart)
library(ggplot2)
library(corrplot)
library(tidyr)
```

# Examine policy_clean_0imputed first
```{r}
file_path <- "../02_CleanData/policy_clean_0imputed.parquet"
df <- read_parquet(file_path, as_tibble = TRUE)
#View(df)
#head(df)
#str(df)
```


#1 Explore 

```{r}
# Select continuous variables for correlation examination
# comment
df_num <- subset(df, select = c(basementenclosurecrawlspacetype, censustract,crsdiscount,deductibleamountinbuildingcoverage, deductibleamountincontentscoverage, federalpolicyfee, latitude, longitude, policycost, policycount, reportedzipcode, ratemethod, totalbuildinginsurancecoverage, totalcontentsinsurancecoverage))

```


```{r}
# Examine correlation between all numeric variables 
cormat <-cor(df_num, use = "pairwise.complete.obs")
```

```{r}
corrplot(cormat, tl.col = "red", tl.srt = 45, bg = "White",
         title = "\n\n Correlation Plot of Flood Data",
         type = "lower")
dev.copy(jpeg, filename="Correlation Plot of Flood Data.jpg");
dev.off ()
```


```{r}
# Looking for Spearman correlation (checks nonlinear correlation too eg y=x3 ha Spearman correlation of 1)
cormat_nonlin <- cor(df_num, use = "pairwise.complete.obs", method="spearman")
cormat_nonlin
```

```{r}
corrplot(cormat_nonlin, tl.col = "red", tl.srt = 45, bg = "White",
         title = "\n\n Correlation Plot of Flood Data with Spearman Method",
         type = "lower")

dev.copy(jpeg, filename="Correlation Plot of Flood Data using Spearman.jpg");
dev.off ()
```

## Remove Multicollinearity with cutoff 0.6


```{r}
# Multicollinearity
# Check the variables of highly correlated

highly_corelated = findCorrelation(cormat, cutoff = 0.6)

highlyCor_Col = colnames(df_num)[highly_corelated]
highlyCor_Col

```

```{r}
# Now, we remove highly correlated variables from original dataset and create cleaner dataset, the dataset now contains 41 columns

df_clean = df[, -which(colnames(df) %in% highlyCor_Col)]
dim(df_clean)
View(df_clean)
```
# Run linear regression

```{r}
fit = lm(totalinsurancepremiumofthepolicy ~., df_clean)
summary(fit)
```

## from the output, we can remove some insignificant variables

```{r}
fit1 = lm(totalinsurancepremiumofthepolicy ~. -censustract -occupancytype -policytermindicator -reportedzipcode -basementonly -mobilehomeortrailer -floodzone_highrisk -floodzone_modrisk -floodzone_undetermined, df_clean)
summary(fit1)
```
```{r}
vif(fit1)
```

# Choose a VIF cutoff under which a variable is retained (Zuur et al. 2010) 
# vif>10  multi-collinearity: remove variables with vif > 10
## Create the final dataset for further analysis 

```{r}
df_final <- subset(df_clean, select = -c(censustract, occupancytype, policytermindicator, reportedzipcode, basementonly,elevationdifference, mobilehomeortrailer, floodzone_highrisk, floodzone_modrisk, floodzone_undetermined, policyterminationdate, not_condo, u_condo, policyeffectivedate))

View(df_final)
```

```{r}
# count NA values in each column
colSums(is.na(df_final))

```

# remove all the rows with NA values (22458 rows ~ 1% of dataset)
```{r}
row.has.na <- apply(df_final, 1, function(x){any(is.na(x))})
sum(row.has.na)
df_final_filtered <- df_final[!row.has.na,]
```
```{r}
# count NA values in each column
colSums(is.na(df_final_filtered))

```


```{r}
# Select only numerical columns for data analysist (leave data type in df_final)
# df_num includes 21 variables

df_num <- subset(df_final_filtered, select = -c(originalconstructiondate, originalnbdate))

View(df_num)
```

```{r}
# categorical columns
df_cat <- subset(df_num, select = c(basementenclosurecrawlspacetype, construction, elevatedbuildingindicator, postfirmconstructionindicator, primaryresidenceindicator, lowerflooronly, upperandlowerfloors, basementandabove, morethan1floor))
lapply(df_cat, unique)
```
```{r}

# Exporting the dataframe to clean folder

# df_final includes numeric (df_num) and 4 "date" columns

file_path3 <- "../03_EDA/df_final_filtered.parquet"
write_parquet(df_final, file_path3)

# df_num includes only numeric variables for analysis
file_path4 <- "../03_EDA/df_num.parquet"
write_parquet(df_num, file_path4)

```


# Import data again to avoid run all above commands
```{r}
file_path <- "../03_EDA/df_num.parquet"
df_num <- read_parquet(file_path, as_tibble = TRUE)

```

1. Stepwise regression

```{r}
scaledData = as.data.frame(scale(df_num[,c(3,4,5,7,8,9,10,11,14,15)])) # standardize all numerical variables
scaledData <- cbind(df_num[,c(1,2,6,12,13,17,18,19,20)],scaledData,df_num[,16]) # Add categorical columns  back in

colnames(scaledData)[16] <- "totalinsurancepremiumofthepolicy"
```



```{r}
ctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 2)

lmFit_Step <- train(totalinsurancepremiumofthepolicy ~ ., data = scaledData, "lmStepAIC", scope = 
                 list(lower = totalinsurancepremiumofthepolicy~1, upper = totalinsurancepremiumofthepolicy~.), direction = "backward",trControl=ctrl, na.action=na.exclude)

```



```{r}
mod_Step = lm(totalinsurancepremiumofthepolicy ~ basementenclosurecrawlspacetype + construction + elevatedbuildingindicator + 
    postfirmconstructionindicator + primaryresidenceindicator + 
    lowerflooronly + upperandlowerfloors + basementandabove + 
    morethan1floor + crsdiscount + deductibleamountinbuildingcoverage + 
    deductibleamountincontentscoverage + latitude + longitude + 
    numberoffloorsininsuredbuilding + policycount + totalbuildinginsurancecoverage + 
    totalcontentsinsurancecoverage,
    data = scaledData)
summary(mod_Step)
```

## LASSO
```{r}
## Variable selections using Lasso

train_con <- trainControl(method = 'cv', number = 5) # using 5 folds cv

lasso <- train(totalinsurancepremiumofthepolicy ~., scaledData,
               method = 'lasso',
               preProc = c('scale', 'center'),
               trControl = train_con
              )
#lasso
```

```{r}
# Get coef

predict(lasso$finalModel, type = "coef", mode = "fraction", s = as.numeric(lasso$bestTune))

# We can further discard variables with coefficients reduced to zero
```

# From the Lasso Regression models, we can discard the variables with coeeficients decreasing to zero, in this case we will remove variable "lowerflooronly"

```{r}
df_num = subset(df_num,select=-c(lowerflooronly)) 
View(df_num)
```

```{r}
for (col in c('construction', 'elevatedbuildingindicator', 'numberoffloorsininsuredbuilding', 'postfirmconstructionindicator', 'primaryresidenceindicator', 'upperandlowerfloors', 'basementandabove','morethan1floor')) {
  plot <- ggplot(data = df_num,
                 aes_string(x = col, y = 'totalinsurancepremiumofthepolicy', group = col, fill = col)) + 
            geom_boxplot(show.legend = FALSE) + 
            ggtitle(glue::glue("Boxplot of Total Insurance Premium per {col}"))
  print(plot)
}
```


```{r}
for (feat in c('construction', 'elevatedbuildingindicator', 'numberoffloorsininsuredbuilding')) {
  plot <- ggplot(data = df_num, aes_string(x = feat, y = 'totalinsurancepremiumofthepolicy', group = 'primaryresidenceindicator', fill = 'primaryresidenceindicator', col = 'primaryresidenceindicator')) + 
    geom_jitter() + 
    geom_smooth(method = 'lm') +
    ggtitle(glue::glue("Charges vs {feat}"))  
  print(plot)
  dev.copy(jpeg, filename="{col}.jpg");
  dev.off ()
}
```



```{r}
# Examine correlation between all numeric variables 
cormat <-cor(df_num, use = "pairwise.complete.obs")
```


```{r}
corrplot(cormat, tl.col = "red", tl.srt = 45, bg = "White",
         title = "\n\n Correlation Plot of Flood Data",
         type = "lower")
dev.copy(jpeg, filename="Correlation Plot of Flood Data_NewData.jpg");
dev.off ()
```


```{r}
# Exporting the dataframe to Modeling folder

# df_num includes only numeric variables for analysis
file_path4 <- "../04_Modeling/df_num_impute0.parquet"
write_parquet(df_num, file_path4)

```

