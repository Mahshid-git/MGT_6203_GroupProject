---
title: "Untitled"
author: "Anh Tran"
date: "4/3/2022"
output: html_document
---
# This part will involve all classification models

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Remove previous data from environment
rm(list = ls())
```

```{r include=FALSE}
if (!require("sjPlot")) install.packages("sjPlot")
if (!require("tidyverse")) install.packages("sjPlot")

library(arrow) # needed to read parquet file
library(plyr)
library(dplyr)
library(car)
library(caret)
library(rattle)
library(rpart.plot)
library(rpart)
library(ggplot2)
library(corrplot)
library(sjPlot)
library(gridExtra)
library(tidyverse)
library(rsample)
library(randomForest)
library(janitor)
library(glmnet)
library(tree)
library(RColorBrewer)
library(gridExtra)
library(pls)
```


```{r}
file_path <- "../04_Modeling/df_num_impute0.parquet"
df1 <- read_parquet(file_path, as_tibble = TRUE)
View(df1)
```

### Note: should scale numeric data before doing analysis. This file exclude 2 columns of "date" 

```{r}
df = as.data.frame(df1[,c(2,3,5,6,12,13,14)]) # standardize all numerical variables

df <- cbind(df1[,c(1,4,7,8,9,10,11,16,17,18,19)],df,df1[,15]) # Add categorical columns  back in

View(df)
```


# Splitting data to 70% training, 30% testing

```{r}
set.seed(100)

size <- floor(0.7*nrow(df))
train_ind <- sample(seq_len(nrow(df)), size = size)

train <- df[train_ind, ]
test <- df[-train_ind, ]
```

#1

```{r}
rsquared <- function(pred){
  if (length(pred)==length(test$totalinsurancepremiumofthepolicy)){
    r2 = 1 - (sum((test$totalinsurancepremiumofthepolicy-pred)^2)/sum((test$totalinsurancepremiumofthepolicy-mean(test$totalinsurancepremiumofthepolicy))^2))
  }
  if (length(pred)==length(train$totalinsurancepremiumofthepolicy)){
    r2 = 1 - (sum((train$totalinsurancepremiumofthepolicy-pred)^2)/sum((train$totalinsurancepremiumofthepolicy-mean(train$totalinsurancepremiumofthepolicy))^2))
  }
  return (r2)
}


MSE <- function(pred){
  if (length(pred)==length(test$totalinsurancepremiumofthepolicy)){
    mse = sum((test$totalinsurancepremiumofthepolicy-pred)^2)/length(test$totalinsurancepremiumofthepolicy)
  }
  if (length(pred)==length(train$totalinsurancepremiumofthepolicy)){
    mse = sum((train$totalinsurancepremiumofthepolicy-pred)^2)/length(train$totalinsurancepremiumofthepolicy)
  }
  return (mse)
}
```


```{r}
linear.bwd <- step(lm(totalinsurancepremiumofthepolicy ~., data= train), direction = c("backward"))

bwd.pred.train = predict(linear.bwd, train)
mse.bwd.train = MSE(bwd.pred.train)
r2.bwd.train = rsquared(bwd.pred.train)

bwd.pred.test = predict(linear.bwd, test)
mse.bwd.test = MSE(bwd.pred.test)
r2.bwd.test = rsquared(bwd.pred.test)
```

```{r}
summary(linear.bwd)
```



























#1. Linear Regression

```{r}

lm_model = lm(totalinsurancepremiumofthepolicy ~., data = train)
summary(lm_model)
```


```{r}
plot_model(lm_model, show.values = TRUE, value.offset = 0.4,sort.est = TRUE, title = "Estimates of Linear Regression")

dev.copy(jpeg,filename="Linear_Estimates_Plot.jpg");
dev.off ()
```

```{r}
par(mfrow = c(2,2))
plot(lm_model)

dev.copy(jpeg, filename="Linear_Residues_Plot.jpg");
dev.off ()
```


```{r}
lm_pred <- predict(lm_model, test)

```


```{r}
lm_data <- cbind(Actual = test$totalinsurancepremiumofthepolicy, Predicted = lm_pred)
#View(lm_data)
```

```{r}
actuals_preds <- data.frame(lm_data)

# Min-Max Accuracy Calculation
min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))  
min_max_accuracy
# => 61%, min_max accuracy

```

```{r}
# find the error
Error <- actuals_preds$Actual - actuals_preds$Predicted
actuals_preds1 <- cbind(actuals_preds, Error)
View(actuals_preds1)

rmse <- sqrt(mean((actuals_preds1$Error)^2))
rmse
```

#2. PCA

```{r}
#PCA
library(stats)  # for prcomp()
library(DAAG)
library(GGally)
library(devtools)
require(ggbiplot)
```
```{r}
pcr.model = pcr(totalinsurancepremiumofthepolicy ~., data = train, scale = TRUE, validation = "CV")
validationplot(pcr.model, val.type="MSEP", main = "totalinsurancepremiumofthepolicy", ylab = "Mean Squared Error")
```



```{r}
summary(pcr.model)
```


```{r}
pcr.pred5.train = predict(pcr.model, train, ncomp = 5)
mse.pcr5.train = MSE(pcr.pred5.train)
r2.pcr5.train = rsquared(pcr.pred5.train)

pcr.pred5.test = predict(pcr.model, test, ncomp = 5)
mse.pcr5.test = MSE(pcr.pred5.test)
r2.pcr5.test = rsquared(pcr.pred5.test)

pcr.pred9.train = predict(pcr.model, train, ncomp = 9)
mse.pcr9.train = MSE(pcr.pred9.train)
r2.pcr9.train = rsquared(pcr.pred9.train)

pcr.pred9.test = predict(pcr.model, test, ncomp = 9)
mse.pcr9.test = MSE(pcr.pred9.test)
r2.pcr9.test = rsquared(pcr.pred9.test)

```





```{r}
PCA <- prcomp(df[,1:18], scale = TRUE)  # apply PCA

summary(PCA)
```


```{r}
# Common function to display PCA related plots in 2x2 grid
screeplot(PCA, type='l')
dev.copy(jpeg, filename="PCA_ScreePlot.jpg")
dev.off ()

bplot = ggbiplot(PCA,
                 choices = c(1,2),
                 obs.scale =1, var.scale =1,
                 circle = TRUE,
                 ellipse = TRUE,
                 ellipse.prob = 0.68)

print(bplot)

dev.copy(jpeg, filename="PCA_Plot.jpg")
dev.off ()

```

```{r}
R2 <- data.frame(n_PCA = numeric(), R2_PCA = numeric(), R2_cross_val = numeric()) #create a vector to store the R-squared values

for (i in 1:18) {
  pc <- PCA$x[,1:i]  # use some i principal components from 4 to 10
  pc_data <- cbind(df[,19], pc)  # create data set
  
  model <- lm(V1~.,data = as.data.frame(pc_data)) # fit model
  R2_PCA <- 1 - sum(model$residuals^2)/sum((df$totalinsurancepremiumofthepolicy -        mean(df$totalinsurancepremiumofthepolicy))^2) # calculate R-squared for PCA model

  
  cross_val <- cv.lm(as.data.frame(pc_data), model, m=5) # cross-validate 
  R2_cross_val <- 1 - attr(cross_val,"ms")*nrow(df)/sum((df_filter$totalinsurancepremiumofthepolicy - mean(df$totalinsurancepremiumofthepolicy))^2) # calculate R-squared
  
  R2[nrow(R2)+1,]<- c(i, R2_PCA, R2_cross_val)
 }

```



```{r}

plot(R2$R2_cross_val, xlab = "Principal Component", ylab = "Cross-validated R-squared with this many principal components", x = R2$n_PCA, ylim =c(0,1),type = "b")
```


## Lasso
```{r}
xtrain = model.matrix(totalinsurancepremiumofthepolicy ~.,train)[,-1]
ytrain = train$totalinsurancepremiumofthepolicy
xtest = model.matrix(totalinsurancepremiumofthepolicy ~.,test)[,-1]
ytest = test$totalinsurancepremiumofthepolicy

cv.lasso.out = cv.glmnet(xtrain, ytrain, alpha=1)
bestlam.lasso = cv.lasso.out$lambda.min
i <- which(cv.lasso.out$lambda == cv.lasso.out$lambda.min)
mse.min.lasso <- cv.lasso.out$cvm[i]

lasso.model = glmnet(xtrain, ytrain, alpha=1, lambda=bestlam.lasso)

lasso.pred.train = predict(lasso.model, newx=xtrain)
mse.lasso.train = MSE(lasso.pred.train)
r2.lasso.train = rsquared(lasso.pred.train)

lasso.pred.test = predict(lasso.model, newx=xtest)
mse.lasso.test = MSE(lasso.pred.test)
r2.lasso.test = rsquared(lasso.pred.test)
```

```{r}
lasso_plot <- ggplot(mapping = aes(x=log(cv.lasso.out$lambda), y=cv.lasso.out$cvm)) +
  geom_point() +
  geom_point(aes(x=log(bestlam.lasso), y=mse.min.lasso, size = 2), show.legend = FALSE, color="red") +
  geom_errorbar(aes(ymin=cv.lasso.out$cvm-cv.lasso.out$cvsd, ymax=cv.lasso.out$cvm+cv.lasso.out$cvsd), color="gray") +
  xlab("Log(lambda)") +
  ylab("Mean Squared Error") +
  labs(title = "Optimal Lambda for Lasso Regression", subtitle = paste("Best Lambda: ", bestlam.lasso)) +
  theme_classic()

```

```{r}
lasso.coef <- rownames_to_column(data.frame(coef(lasso.model)[,1]), var = "Variable") %>%
  rename(Coefficient = coef.lasso.model....1.)

lasso.coef <- lasso.coef %>%
  filter(Variable != "(Intercept)") %>%
  arrange(desc(abs(Coefficient)))

coef.compare <- lasso.coef %>%
  left_join(ridge.coef, by = "Variable") %>%
  rename("Lasso Coefficient" = Coefficient.x) %>%
  rename("Ridge Coefficient" = Coefficient.y)

coef.compare
```


